+++
categories = []
date = 2021-07-12T16:00:00Z
tags = ["Elasticsearch"]
title = "Elasticsearch分片副本那些事"
url = "/post/elasticsearch-shard-replica"

+++
#### 前言

从某种角度上说，ES是十分易用的，利用ES完成一些基本的写入和查询操作，只需要简单看下文档就能学会。但是ES又有很多配置可以自定义，当你有实际的业务需要时，如何能有效利用现有的资源达到比较好的时延和吞吐量确又非常困难。本文就聊一下分片（shard）和副本（replica），来看看究竟应该如何选择一个合适的分片和副本数。

#### 分片副本是什么

分片类似于数据库的分库分表，将一个索引里的数据分到不同的分片中。在写入过程中，通过相应的路由手段（默认规则是分片编号=hash(_id)%总分片数）写入相应的分片。在查询过程中，会分别查询所有分片并将结果汇总得到最终查询结果，这样就可以将非常大量的索引数据分散到不同的分片中，由于每个分片的查询都使用一个线程，这样可以有效地减小单次查询的时延。

副本其实很容易理解，用处就是保证当部分节点掉出集群时保证ES集群的可用性。副本数量越多，能容忍掉节点的数量就越多。另外，副本也是一种分片，也可以执行查询任务。

#### 分片副本数量应该怎么选

副本数量比较好选，根据你需要的可用性选择就好。另外，副本越多，写入消耗就越大（相当于写了不止一份的数据）。

接下来，我们主要聊一下查询过程中一个节点上的分片数量应该有几个（这里说的分片就包含了副本，因为副本也会参与到查询中去）。

既然分片数量增加，单个线程可以更快地完成单shard的查询，那么是不是分片越多越好呢？其实不然，分片数量过多会导致以下三个问题：

1. 多个shard并发查询会使用到更多的线程数，这样会增大CPU上下文切换次数，可能会增大时延
2. 一次查询会查询多个shard，并将结果合并，这会受木桶效应影响，一旦某一个或几个shard的查询时延增大，总的查询时延也会受到影响。（在这种情况下，网络波动是一个容易出现的影响因素）
3. ES使用主从机制，shard信息的元数据需要master节点管理。当shard数量增多时，master节点同步元数据的压力会增大，可能会影响集群的可用性。ES在7版本之后增加了一个参数cluster.max_shards_per_node限制单节点shard数量不超过1000

分片最少一个节点一个（shard数量为1，replica数量为node数-1），这种情况下由于无法利用分片并发查询，时延会比较高。那么最多应该是多少呢？

其实这里可以参考ES源码中SEARCH线程池的设置，保持分片最多不超过1.5倍核数+1。这是为什么呢？

这里我可以举一个形象的例子，假设CPU核数是高速路的车道数C，每一条车道对应一个核，收费站数量则是线程数P。现在假设P=C=10，并且每一辆车都用ETC过收费站（假设占了10个CPU时间片），这种情况下每一个任务（车）都正好占了一个核（收费站），此时CPU被占满。假设所有ETC换成了人工收费口，过收费口时有一半的时间都被浪费在了掏手机扫码上（5个时间片IO，5个时间片占用CPU），这种情况下进去10辆车，只能出5辆车，CPU占用率只有一半。此时如果想要占满CPU，那么就需要提高线程数，让一个收费员负责两个车道，这样分下来就可以进去10辆车，出来10辆车了。

通过这个例子，可以推断出：ES假设了平均情况下一个查询时间中CPU时间:IO时间=2:1，因为这样设置SEARCH线程可以将CPU跑满。那么单节点分片数量的上限可以认为是1.5倍核数+1，因为这种情况下CPU会被占满。

#### 吞吐量和时延

下面再来说总结讨论一下分片数是如何影响吞吐量和时延的。事实上，吞吐量不会收到分片数量的影响。举个例子，假设CPU核数是4，单节点有1个分片和单节点有4个分片的情况下，在CPU占用率相同的情况下，单位时间内响应的请求数量是一样多的。（比如跑慢满4个核，1个分片单位时间可以响应4个请求，4个分片单位时间内也可以响应四个请求）。

时延这个指标上面已经聊过了，单分片时延最久，线程数多时反而时延又会劣化。所以要综合考量。

#### 总结

本文聊了一下ES分片副本的基本选择思路，需要注意的是，本文给出的结论仅仅是启发式的，并且没有考虑很多实际场景中的因素，仅供参考。


#### 参考链接
1. [如何估算吞吐量以及线程池大小](https://chanjarster.github.io/post/concurrent-programming/throughput-and-thread-pool-size/)
2. [并行、延迟与吞吐量](https://chanjarster.github.io/post/concurrent-programming/parallel-latency-throughput/)
3. [聊聊 Elasticsearch 的查询毛刺](https://www.easyice.cn/archives/361)
4. [How many shards should I have in my Elasticsearch cluster?](https://www.elastic.co/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster)