<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Fan Jingbo's Blog</title><link>https://fanjingbo.com/</link><description>Recent content on Fan Jingbo's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 28 Nov 2020 16:00:00 +0000</lastBuildDate><atom:link href="https://fanjingbo.com/index.xml" rel="self" type="application/rss+xml"/><item><title>对于Linux中oom-killer的简单探究</title><link>https://fanjingbo.com/post/oom-killer/</link><pubDate>Sat, 28 Nov 2020 16:00:00 +0000</pubDate><guid>https://fanjingbo.com/post/oom-killer/</guid><description>最近在对Elasticsearch集群进行压力测试的时候发现，当我不停的对集群进行创建索引操作时，集群的master节点总会莫名其妙的挂掉。表现是ES进程退出，并且JVM没有生成相应的dump文件。我陷入了疑惑，后来经过别人指点我才知道原来进程是被Linux中的oom-killer杀掉了。由于之前没有了解过，所以我花了一段时间了解了一下oom-killer的机制，还顺带看了一些Linux源码。
一、Linux内存分配参数vm.overcommit_memory Linux的内存是先申请，然后再按需分配的，所以有可能一个进程申请了200MB的内存，但是实际只使用了100MB。所以为了最大化内存利用率，Linux支持过度申请，也就是所谓的overcommit。Linux内核通过overcommit_memory这个参数决定对待申请内存的策略，包含三个值，内核文档说明如下：
0 - Heuristic overcommit handling. Obvious overcommits of address space are refused. Used for a typical system. It ensures a seriously wild allocation fails while allowing overcommit to reduce swap usage. root is allowed to allocate slightly more memory in this mode. This is the default. 1 - Always overcommit. Appropriate for some scientific applications. Classic example is code using sparse arrays and just relying on the virtual memory consisting almost entirely of zero pages.</description></item><item><title>Java的匿名类、匿名函数与方法引用</title><link>https://fanjingbo.com/post/java-anonymous-class-lambda-method-reference/</link><pubDate>Sat, 07 Nov 2020 16:00:00 +0000</pubDate><guid>https://fanjingbo.com/post/java-anonymous-class-lambda-method-reference/</guid><description>一、前言 从我接触Java伊始，就见过了很多匿名函数，最典型的是Java的多线程，写法如下：
new Thread(() -&amp;gt; { for (int i = 0; i &amp;lt; 100; i++) { System.out.println(i); } }).start(); 起初我十分不理解这是一种什么写法，经过查询也只知道这是一种叫Lambda函数的东西，看了很多文章之后也没能很好的理解。现在是终于搞懂了，所以写一篇总结来帮助我梳理一下相关知识。
二、匿名类与匿名函数 匿名类，顾名思义就是没有类名字的类。匿名函数相对应的就是没有名字的函数。因为没有名字，两者都适用于定义一个不需要被重用的类或者方法的场景。其实这两者是共通的。在我的理解里，匿名函数是对匿名内部类的进一步简化抽象。对于匿名类来说，一般都是需要实现多个方法时使用的。例子如下：
interface Pet { String getName(); String getAge(); } class PetShop { static void sell (Pet pet) { System.out.println(&amp;quot;Pet name is &amp;quot; + pet.getName() + &amp;quot;\nPet age is &amp;quot; + pet.getAge()); } public static void main(String[] args) { PetShop.sell(new Pet() { @Override public String getName() { return &amp;quot;Ruby&amp;quot;; } @Override public String getAge() { return &amp;quot;10&amp;quot;; } }); } } 可以看到，在这个例子中，PetShop这个类的sell方法会用到Pet接口的实现类，但是这个实现类只需要使用一次，不需要复用（因为这里面逻辑是出售）。在这种情况下就可以使用匿名类，在不定义类名的情况下实现两个方法即可。</description></item><item><title>由缓存穿透想到的——HashSet和布隆过滤器</title><link>https://fanjingbo.com/post/bloomfilter/</link><pubDate>Wed, 26 Aug 2020 16:00:00 +0000</pubDate><guid>https://fanjingbo.com/post/bloomfilter/</guid><description>一、缓存穿透 设想一种高并发场景，后台服务在查询数据库（如Mysql）之前先查缓存（如Redis）。如果缓存失效，大量无法在数据库中查询到结果的请求（如数据库中没有的ID查询）没有在Redis中查到内容，就会“穿透”我们的缓存服务，直接打到数据库上。这就有可能导致数据库因为压力过大而挂掉。
这里要注意，缓存穿透与缓存击穿是不同的，击穿主要指大量请求查询某一个key的时候，这个key在缓存中是失效状态。这些查询就会“击穿”缓存。还有一个概念叫缓存雪崩，指的就是很多key都在缓存中失效了（或者干脆缓存服务挂掉了），导致数据库被打挂的情况。
可以这样理解，从穿透到击穿再到雪崩，是一个严重程度逐步递进的过程。
针对缓存穿透的问题，有两个解决方法：一个是缓存空值，也就是将值为null写入缓存；另一个就是加入一个过滤器，这个过滤器的作用是识别key是否在数据库中存在，如果存在则继续进入缓存——数据库查询，如果不存在则直接返回结果。
这种过滤器方法实际上可以用HashSet来实现。
二、HashSet的原理 1.基本原理 在Java语言中，HashSet是一个数据结构实现类，实现了Set（集合）接口。这个数据结构主要特点就是无序并且唯一。对于缓存穿透的场景，只需要将数据库中的所有key写入HashSet（add方法），然后就可以通过contains方法查到key是否存在，从而实现这个过滤器。
2.源码分析 那么HashSet是如何实现add过程的去重和contains方法的呢？这时候就需要看代码了。可以发现HashSet实际上是复用了HashMap的方法（定义了一个空对象PRESENT填充到value中，十分巧妙）：
private transient HashMap&amp;lt;E,Object&amp;gt; map; // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); /** * Constructs a new, empty set; the backing &amp;lt;tt&amp;gt;HashMap&amp;lt;/tt&amp;gt; instance has * default initial capacity (16) and load factor (0.75). */ public HashSet() { map = new HashMap&amp;lt;&amp;gt;(); } public boolean add(E e) { return map.</description></item><item><title>CTF从零单排（二）—— bof (pwnable.kr)</title><link>https://fanjingbo.com/post/ctf2/</link><pubDate>Sat, 15 Aug 2020 16:00:00 +0000</pubDate><guid>https://fanjingbo.com/post/ctf2/</guid><description>一、题目分析 查看题目给出的信息，一个C代码文件和一个可执行文件，C代码文件如下：
#include &amp;lt;stdio.h&amp;gt; #include &amp;lt;string.h&amp;gt; #include &amp;lt;stdlib.h&amp;gt; void func(int key){ char overflowme[32]; printf(&amp;quot;overflow me : &amp;quot;); gets(overflowme); // smash me! if(key == 0xcafebabe){ system(&amp;quot;/bin/sh&amp;quot;); } else{ printf(&amp;quot;Nah..\n&amp;quot;); } } int main(int argc, char* argv[]){ func(0xdeadbeef); return 0; } 可以看出这道题考的是栈溢出，从标准输入读取的数据覆盖掉func传入的参数值即可提权。关键问题就是如何构造这个数据。
二、题解 使用gdb对可执行文件bof进行分析：
首先使用start开始执行，方便之后使用地址打断点
然后使用disas func查看func函数的汇编代码
找到get函数调用后的比较语句并打断点
使用c（continue）继续执行代码
输入AAAAAA，使用x /40xw $esp查看栈数据。A用16进制表示是41，可以看到第一个A到deadbeef相差52个字节。因此我们只需要构造52个A加上cafebabe即可。
使用Python的pwn库：
成功拿到flag
由此可见，C代码中使用gets有多危险，使用gcc编译时也会提示gets的危险性。
三、遗留问题 虽然题目参考着其他人的题解做了出来，但是目前还是有两个问题我还没想明白，在这里记录一下：
发现如果使用gcc默认编译选项编译出来的可执行文件（可能与64位有关），deadbeef参数在低地址，标准输入参数在高地址，不符合栈帧是从高地址向低地址生长（申请）的原则，很奇怪
为什么0xdeadbeef写入栈中的时候没有按照小端原则？
问题已解决，因为0xdeadbeef是int类型，占据了4个字节，所以无所谓大端小端，在内存中就是以0xdeadbeef形式保存的</description></item><item><title>travis-ci自动部署博客到腾讯云COS</title><link>https://fanjingbo.com/post/travis-ci_to_cos/</link><pubDate>Fri, 05 Apr 2019 03:00:00 +0000</pubDate><guid>https://fanjingbo.com/post/travis-ci_to_cos/</guid><description>我的博客使用的是hugo，博客一直放在腾讯云COS上，只要域名备案就能使用，加上CDN速度也不错。但是使用腾讯云COS更新博客，需要登录腾讯云控制台，手动把本地hugo生成的文件上传到COS上，十分痛苦并且一点也不geek。与之形成鲜明对比的就是netlify，部署十分方便，只要把hugo文件夹设置成github repo，仓库一更新，网站就会自动部署。再搭配上forestry.io的hugo cms，博客更新就可以完全放在云上。因此我就想该如何解放双手，将上传过程简化。持续集成服务（Continuous Integration, CI）就是一个好的选择。
Travis CI 因为之前看到别人github的repo里面有.travis.yml文件，对于Travis CI有一定了解，因此我决定使用这个持续集成服务。在简单看了文档之后，我发现配置十分智能，直接使用github账号登录，然后就可以绑定对应的repo。之后就可以在对应repo里面加入.travis.yml文件，在这个文件里面就可以加入脚本等内容，Travis CI就会根据这个配置文件进行对应的构建和部署。
举个例子：
language: python python: - &amp;#34;2.6&amp;#34; - &amp;#34;2.7&amp;#34; - &amp;#34;3.3&amp;#34; - &amp;#34;3.4&amp;#34; - &amp;#34;3.5&amp;#34; - &amp;#34;3.5-dev&amp;#34; # 3.5 development branch - &amp;#34;3.6&amp;#34; - &amp;#34;3.6-dev&amp;#34; # 3.6 development branch # command to install dependencies install: - pip install -r requirements.txt # command to run tests script: - pytest 可以看到，配置文件中可以设置语言和版本，安装依赖并且运行脚本，相当的自由。我们的构建环境需要Go和Python两个环境（需要hugo生成静态文件，需要Python上传静态文件到腾讯COS），Travis CI是可以使用两种语言环境的，如下：
matrix: include: - language: go ... - language: python ... 但是在尝试的过程中遇到了两个问题，一个是golang和hugo在Travis CI中的构建过程太慢</description></item><item><title>CTF从零单排（一）—— collision (pwnable.kr)</title><link>https://fanjingbo.com/post/ctf1/</link><pubDate>Mon, 11 Mar 2019 16:00:00 +0000</pubDate><guid>https://fanjingbo.com/post/ctf1/</guid><description>一、前言 最近突然对CTF产生了兴趣，感觉能从中学到很多东西。并且我发现很多关于CTF的解法文章对我这样的小白很不友好，因此我打算新开一坑，从零基础的角度详细地记录一下CTF的题解。
二、题目及分析 今天做的题目是pwnable.kr里面的第二题——collision（第一题比较简单，就直接跳过了）。先是用ssh连到一个提供的主机上，发现目录下有三个文件。 col.c的代码如下：
#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;string.h&amp;gt;unsigned long hashcode = 0x21DD09EC; unsigned long check_password(const char* p){ int* ip = (int*)p; int i; int res=0; for(i=0; i&amp;lt;5; i++){ res += ip[i]; } return res; } int main(int argc, char* argv[]){ if(argc&amp;lt;2){ printf(&amp;#34;usage : %s [passcode]\n&amp;#34;, argv[0]); return 0; } if(strlen(argv[1]) != 20){ printf(&amp;#34;passcode length should be 20 bytes\n&amp;#34;); return 0; } if(hashcode == check_password( argv[1] )){ system(&amp;#34;/bin/cat flag&amp;#34;); return 0; } else printf(&amp;#34;wrong passcode.</description></item><item><title>GPG牛刀小试</title><link>https://fanjingbo.com/post/gnupg/</link><pubDate>Mon, 21 Jan 2019 11:09:10 +0800</pubDate><guid>https://fanjingbo.com/post/gnupg/</guid><description>一、GPG简介 GPG（或GnuPG）是自由软件基金会（Free Software Foundation）开发的程 序，是基于商业加密软件PGP（Pretty Good Privacy）的作者（Phil Zimmermann）倡导提出的开放标准OpenPGP实现的，主要作用是加密，签名和生成非对称密钥对。
二、非对称加密与数字签名 要知道什么是非对称加密，就要先知道什么是对称加密。对称加密就是加密和解密使用相同的密钥，或者两个可以简单地相互推算的密钥。比如，经典的凯撒密码，就是将字母表进行移位映射加密，A加密为B，B加密为C，这样，反向移位就可以解密。然而，对称加密如果密钥泄露，安全就不复存在了。非对称加密就可以解决这个问题。
简单来说，非对称加密就是使用公钥加密传输，使用私钥解密。比如说Alice要向Bob传递信息，Bob要先生成非对称密钥对，自己保留私钥，给Alice公钥。Alice使用Bob的公钥加密信息，Bob拿到加密信息后，使用自己的私钥解密查看信息。这就避免了因为密钥丢失导致的安全问题。
而数字签名，也是利用非对称加密技术的应用。首先，用Bob的私钥对文件加密（实际是文件的hash结果），加密的结果作为数字签名发送给Alice。Alice拿到数字签名和文件，使用Bob的公钥解密数字签名，将得到的结果与文件的hash结果作对比，如果一致，证明文件确实是Bob签署的。
三、GPG上手 本来我写了一些常用命令，后来发现没啥意思，命令随便一查就能查到。我就写一些比较有趣的东西吧。
1.Keyring 在密码学中，keyring存储的是key，十分形象，key的ring。在GPG中，如下命令：
gpg --list-keys 可以列出在keyring中的所有key。其实keyring可以看成一个通讯录，里面存储的key可以看做是一个个收件人的信息，消息的发送过程就可以类比成加密。
2.Fingerprint 由于公钥很长，所以使用fingerprint来指代对应的公钥，相当于公钥的ID。不过很多时候，使用公钥生成时输入的姓名和邮箱也可以找到对应的公钥，只不过不是一一对应的关系。
3.公钥签名（Key Signing）和Key Signing Party 在非对称加密中，公钥的有效性十分重要。还是拿Alice和Bob举例子，如果Eve将自己的公钥伪装成Bob的公钥发送给Alice，那么Alice就会用Eve的公钥加密数据，Eve就可以使用自己的私钥解密得到数据。
因此，如果利用数字签名技术，第三个人Dave可以使用他的私钥对Bob的公钥进行签名，表明他认可这个公钥的真实性，这样Alice就可以使用Dave的公钥验证出Dave对这个公钥进行了数字签名。这样Dave就类似于一个担保人，证明该公钥属于Bob。
既然Dave可以签名，那么其他人也可以签名。可以认为签名的人越多，公钥越可信。密码学中，有一个概念是信任网络（Web of Trust）。它的提出者也是PGP的提出者Phil Zimmermann是这样说的：
As time goes on, you will accumulate keys from other people that you may want to designate as trusted introducers. Everyone else will each choose their own trusted introducers. And everyone will gradually accumulate and distribute with their key a collection of certifying signatures from other people, with the expectation that anyone receiving it will trust at least one or two of the signatures.</description></item><item><title>[Leetcode] Add Two Numbers</title><link>https://fanjingbo.com/post/leetcode_add_two_numbers/</link><pubDate>Sun, 13 Jan 2019 14:39:57 +0800</pubDate><guid>https://fanjingbo.com/post/leetcode_add_two_numbers/</guid><description>一、题目描述 链接
二、题目分析 题目很容易理解，将两个用链表表示的数相加，结果也用链表表示，三个链表都是倒序(reverse order)表示的。其实倒序算是简化了题目，如果不倒序实现相加，由于要考虑进位的问题，需要先将链表翻转。 这道题有两种解法：一个是在遍历过程中实现按位的加法；还有一种就比较取巧了，先遍历两个链表，拿到对应的数字，然后相加，再将结果生成链表。 解法一要注意考虑进位的情况和链表节点为空的情况，进位只可能是0或1，通过整除10计算(注：在Python3中//表示整除，在Python2中/表示整除)，其中一个链表节点为空时就只计算另一个链表的对应节点和进位的和。解法一另外还有一种写法，就是只考虑节点存在的情况。 解法二比较简单，需要注意的是要做两次字符串翻转，得到两个链表代表的倒序数字后要翻转一次才能做加法，做完加法的数字要翻转回来成倒序存到链表里。
三、代码 解法一： #第一种写法 head = ListNode(0) L = head flag = 0 while l1 or l2: if not l1: L.next = ListNode((l2.val + flag) % 10) flag = (l2.val + flag) // 10 l2 = l2.next elif not l2: L.next = ListNode((l1.val + flag) % 10) flag = (l1.val + flag) // 10 l1 = l1.next else: L.next = ListNode((l1.val + l2.val + flag) % 10) flag = (l1.</description></item><item><title>Center Loss的Pytorch实现</title><link>https://fanjingbo.com/post/center_loss_pytorch/</link><pubDate>Fri, 16 Mar 2018 08:07:05 +0800</pubDate><guid>https://fanjingbo.com/post/center_loss_pytorch/</guid><description>Center Loss是2016年ECCV的一篇人脸识别文章中加入的新损失函数。原作者是使用Caffe实现的，有很多人实现了各种版本的Center Loss。但是我发现github上唯一的Pytorch版本并没有完全按照作者的方法来实现，我就打算修改一下。以下的思考都是在修改代码的过程中进行的
一、Center Loss的原理 要实现Center Loss，必须知道Center Loss的原理。
Center Loss一般是和Softmax Loss配合使用的，Softmax Loss可以使类间距离变大，而Center Loss可以使类内距离更小，下面的图片能很形象地表现出Center Loss的作用。
Center Loss的流程大致如下：
保存一个参数，这个参数存储的是feature的中心值，我们定义成centers_param 前传过程中计算输入的特征值features与存储的参数之间的均方误差(MSE)
反向传播时，feature的梯度公式如下： 中心值的梯度是由作者定义的，公式如下：
这样就会导致，Center Loss层输入feature的梯度很容易求，直接自动求导即可，但是，中心值的参数就需要手动更新了。
注：作者定义的是变化而不是梯度，所以不需要乘学习率，但是需要乘以作者指定的一个系数。为了方便说明可以简化看作梯度）
二、Pytorch中的backward 那么到底该怎样手动更新呢？要搞清楚这点首先要了解Pytorch中的backward方法
我们看一下官方文档中backward的基本用法
从文档可以看出：
当variables是标量时，不用指定grad_variables（事实上，此时grad_variables为1），这种情况就是一般的loss.backward()这种用法。 当variables为非标量且require_grad为True时，需要指定grad_variables，文档中对grad_variables的解释为“gradient of the differentiated function w.r.t. corresponding variables”，其实意思就是损失函数相对与variables的梯度 因此backward可以实现两种情况，一种是傻瓜式的，给一个loss，backward可以把所有前层require_grad=True的梯度算出来；而另一种是从中间层开始往前算，这种就需要知道grad_variables了。原理和链式法则一模一样。
三、实现Center Loss 到现在，解决方案已经呼之欲出了：进行两次backward即可。如图：
Center Loss层有两个变量，进行loss.backward()，两个变量都会求出对应的梯度。而centers_param.backward(man_set_centers_grad)，则可以直接把man_set_centers_grad赋值给variable的梯度，也就是存储中心值的梯度。那么我们连续进行以上两个backward，就可以实现想要的手动更新。不过需要注意的是，连续两次backward，会把两次梯度累加。所以在第一次backward后使用zero_grad()方法，把梯度置零即可。
我的代码：https://github.com/flyingpot/center_loss_pytorch</description></item><item><title>Selenium踩坑记</title><link>https://fanjingbo.com/post/selenium/</link><pubDate>Wed, 28 Feb 2018 03:39:05 +0800</pubDate><guid>https://fanjingbo.com/post/selenium/</guid><description>一、前言 Selenium是一个浏览器自动化测试工具，支持所有主流的浏览器，并且有各种语言的接口，也就是说通过写代码就可以模拟各种浏览器操作。我主要是用Selenium写一个小脚本，实现某交易平台上的自动场外交易。
Selenium也有化学元素硒的意思
二、环境配置 配置Selenium需要三个组件，一个是Selenium Client API，一个是WebDriver，最后是浏览器。简单来说就是API控制WebDriver，WebDriver控制浏览器，来实现通过代码对浏览器进行操作，流程十分清晰。
首先是Selenium，由于我只会Python(哭)，所以我选择安装Python版本的Selenium
pip install selenium 虚拟环境配置就不再赘述了。
然后是WebDriver，不同的浏览器对应的WebDriver也不同。我这次使用的是Firefox，对应的WebDriver叫geckodriver(https://github.com/mozilla/geckodriver/releases)，下载下来扔到环境变量里即可。
最后也是最简单的——浏览器，四大主流浏览器(Chrome, Edge, Firefox, Safari）全都支持，看你喜好选择。注意WebDriver和浏览器版本要对得上，都升到最新版本就行。
三个组件都装好了，测试一下，打开Python解释器，输入以下代码：
from selenium import webdriver driver = webdriver.Firefox() driver.get(&amp;#34;https://fanjingbo.com&amp;#34;) 如果能弹出浏览器并成功加载网页，说明环境配置成功。
三、Selenium实战 Selenium基本上能实现任何对浏览器的操作，在这里只讨论一些常用方法。
driver.get driver.get方法能使浏览器跳转到相应的网址，并且默认是等所有元素加载完毕语句才结束
driver.refresh driver.refresh能刷新页面，一般用于多次获取某页面里的数据。这里有一个小技巧，现在的页面大多是局部刷新的，我们需要的数据并不需要刷新整个页面，用refresh方法既慢也没必要，所以有时候根据实际情况，可以通过多次调用driver.get方法来实现快速刷新。
driver.find_element_by_*\* 对浏览器进行操作一定少不了元素的定位，这个方法可以用各种方式来定位元素，比如xpath，css selector等等。定位完之后，可以用click()来点击，send_keys()来填充表单
WebDriverWait 比如填充了登录表单，点击了登录按钮，这个时候我们不能对新页面进行操作，因为页面还没有加载完毕。有两种解决方法，一种是直接设置等待几秒钟，Selenium有implicitly_wait()方法，或者直接time.sleep()也可以，但是这种方式存在问题：如果网络有问题，页面加载非常缓慢的话，这种方式就失效了。所以一般都采用第二种方法WebDriverWait，例子如下：
from selenium.webdriver.support.wait import WebDriverWait from selenium.webdriver.support import expected_conditions as expected from selenium.webdriver.common.by import By wb = webdriver.Firefox() wb.get(&amp;#39;https://fanjingbo.com&amp;#39;) wait = WebDriverWait(wb, timeout=10) wait.until(expected.visibility_of_element_located((By.XPATH, &amp;#34;---相应的xpath---&amp;#34;))) 代码实现的就是对应xpath的元素出现之前一直等待。</description></item><item><title>[Leetcode] Heaters</title><link>https://fanjingbo.com/post/leetcode_heaters/</link><pubDate>Mon, 05 Feb 2018 01:44:15 +0800</pubDate><guid>https://fanjingbo.com/post/leetcode_heaters/</guid><description>一、题目描述 链接
二、题目分析 有两个数组，一个数组代表house位置，另一个代表heater位置。这种类型题一般来说都是固定一个数组，遍历另一个数组。固定house，遍历heater明显不对。因为heater的相互位置没有考虑，结果一定偏大。以下图为例，两个数组分别为：[0, 3], [1, 2]，如果分别遍历1和2，则结果至少是2，实际应该是1.所以应该固定heater，遍历house。
思路确定之后，解法就很明显了。解法一：对每个house位置，用二分法找到最近的heater位置，最后取位置的最大值即为解，因为用了二分法，所以heater数组需要先进行排序。解法二：把house和heater两个数组都进行排序，然后遍历house，每次记住最近的heater位置，下次遍历时从记住的位置开始，最后取位置最大值为解。
三、代码 解法一： heaters.sort() res = 0 for house in houses: start = 0 end = len(heaters) - 1 while start + 1 &amp;amp;lt; end: mid = start + (end - start) / 2 if heaters[mid] &amp;gt; house: end = mid else: start = mid res = max(res, min(abs(house - heaters[start]), abs(heaters[end] - house))) return res 解法二： houses.sort() heaters.sort() i, res = 0, 0 for house in houses: while i &amp;amp;lt; len(heaters) - 1 and heaters[i] + heaters[i + 1] &amp;amp;lt;= house * 2: i += 1 res = max(res, abs(heaters[i] - house)) return res</description></item><item><title>Python中list增加元素的几种方法</title><link>https://fanjingbo.com/post/python_add_elements_in_list/</link><pubDate>Thu, 30 Nov 2017 07:51:59 +0800</pubDate><guid>https://fanjingbo.com/post/python_add_elements_in_list/</guid><description>一 我一般会用append方法来把元素增加到list中.但今天我看到一种新方法：
a = [1] a += 2, # a = [1, 2] 感觉挺神奇的，所以我查了一些资料，总结如下.
二 1.元组 上面的2,代表了单元素元组(one element tuple).在元组的表达式中，逗号是必需的，括号则可要可不要.对于单元素元组来说，后面的逗号必须有；而对于多元素元组，只要中间有逗号即可.
1, 1,2,3 2.a+=b和a=a+b的区别 a+=b
&amp;gt;&amp;gt;&amp;gt; a = [1] &amp;gt;&amp;gt;&amp;gt; b = a &amp;gt;&amp;gt;&amp;gt; b += [2] &amp;gt;&amp;gt;&amp;gt; a [1, 2] &amp;gt;&amp;gt;&amp;gt; b [1, 2] a=a+b
" data-lang="python"&amp;gt;&amp;gt;&amp;gt; b = a &amp;gt;&amp;gt;&amp;gt; b = b + [2] &amp;gt;&amp;gt;&amp;gt; a [1] &amp;gt;&amp;gt;&amp;gt; b [1, 2] 对于可变对象，+=操作调用iadd方法，直接在原对象a上进行更新，该方法的返回值是None；+操作调用add方法，返回一个新的对象，原对象不修改，所以b被重新赋值，b指向了一个新的对象.
对于不可变对象，只有add方法，所以两者效果一样.
不仅如此，在list增加元素方面，两者也有不同.
&amp;gt;&amp;gt;&amp;gt; a = [] &amp;gt;&amp;gt;&amp;gt; a = a + 1 Traceback (most recent call last): File &amp;#34;&amp;amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;amp;lt;module&amp;gt; TypeError: can only concatenate list (not &amp;#34;int&amp;#34;) to list &amp;gt;&amp;gt;&amp;gt; a = a + (1,) Traceback (most recent call last): File &amp;#34;&amp;amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;amp;lt;module&amp;gt; TypeError: can only concatenate list (not &amp;#34;tuple&amp;#34;) to list &amp;gt;&amp;gt;&amp;gt; a = a + [1] &amp;gt;&amp;gt;&amp;gt; a [1] "</description></item><item><title>Boyer-Moore Majority Vote算法及相关算法题</title><link>https://fanjingbo.com/post/boyer_moore_majority_vote/</link><pubDate>Fri, 24 Nov 2017 04:35:46 +0000</pubDate><guid>https://fanjingbo.com/post/boyer_moore_majority_vote/</guid><description>一、算法简介 Boyer-Moore Majority Vote算法（以下简称BMMV算法）是用来在一系列元素中查找主要元素的算法，具有O(n)的时间复杂度和O(1)的空间复杂度。该算法在1981年由Robert S. Boyer和J Strother Moore提出。
Tips: Robert S. Boyer和J Strother Moore两人在1977年提出了Boyer-Moore字符串搜索算法，也是一个很经典的算法
二、问题描述 1. Leetcode 169 (Majority Element) 给定含有n个元素的数组，寻找其主元素（出现超过n/2下界次的元素）
题解： 本题有多种解法，排序，哈希表都可以AC。先说一下比较巧妙的排序法。
class Solution: def majorityElement(self, nums): return sorted(nums)[len(nums)//2] 主要原理就是，只要主元素存在，数组索引为len(nums)//2处的值一定是主元素（对于奇数长度的数组，中位数一定是主元素；对于偶数长度的数组，中间的两个数一定都是主元素）。
哈希表的方法见下文。
下面是BMMV算法的实现代码：
class Solution: def majorityElement(self, nums): count = 0 candidate = None for num in nums: if count == 0: candidate = num count += (1 if num == candidate else -1) return candidate 可以看出，BMMV算法思想很简单，初始化count为0，每当count为0时，candidate为数组中下一个数，遍历数组，如果数等于candidate，则count加一，否则减一，最后返回candidate即为主元素</description></item><item><title>Python、$PATH和虚拟环境</title><link>https://fanjingbo.com/post/python_path/</link><pubDate>Mon, 27 Mar 2017 03:26:57 +0800</pubDate><guid>https://fanjingbo.com/post/python_path/</guid><description>一 半年前我在运行一个Python程序的时候，发现运行程序报错，而且怎么也解决不了。当时我还不会用git，但即便会用也无计可施，因为我压根就没改过那段程序。依稀记得当时我情绪爆炸，对出现的问题根本没有头绪。
我的大神室友知道我遇到了问题，在听我说明情况后，轻描淡写地坐下来，打出了一个指令
which python 然后他看了看输出，问我最近有没有装奇怪的东西，我一脸懵逼，但仔细一想确实装了Anaconda（一个Python的科学计算环境）。但是那是一个星期前的事啊。大神不屑地瞟了我一眼，又问我：“你是不是最近重启过？”我一想确实，那天mac有点卡，实在受不了，所以不得已重启了一下。当我还在懵逼的时候，大神已经开始潇洒地敲打键盘，不一会儿就帮我调试好了。“哇！好棒！”我抱着电脑开始跑起自己的程序，无视掉了旁边准备装逼的大神。。。
二 半年过去，Python我也用了不少，但是对于Python包的路径还有像是virtualenv、conda这样的虚拟环境原理还不是很明白，这两天研究了一下，再与当时大神的风骚操作相印证，自己也是明白了一些东西。
1. which命令 具体的参数可以man which看，用处就是在环境变量$PATH中找到命令对应的路径。所以which python输出的就是Python命令的路径
2. python路径 系统安装的python解释器路径是/usr/bin/python，pyhton包的路径是/usr/lib/python/...，可以这样验证：
$ python &amp;gt;&amp;gt;&amp;gt; import sys &amp;gt;&amp;gt;&amp;gt; print(sys.path) [&amp;#39;&amp;#39;, &amp;#39;/usr/lib/python36.zip&amp;#39;, &amp;#39;/usr/lib/python3.6&amp;#39;, &amp;#39;/usr/lib/python3.6/lib-dynload&amp;#39;, &amp;#39;/usr/lib/python3.6/site-packages&amp;#39;] 在import一个包的时候，python解释器会按照这个list从前往后的顺序来寻找这个包，在前面找到就不会继续找了。
3. $PATH PATH这个环境变量可以用echo $PATH来输出查看，作用是记录可执行文件的存放路径。和Python导入模块一样，操作系统也是从前往后依次查找的。
Anaconda会在一个新的地方安装Python环境，如~/anaconda/bin/python和~/anaconda/lib/...，然后在安装过程中会在~/.bashrc这个bash配置文件中加上$PATH：export PATH=&amp;quot;/home/[username]/anaconda/bin:$PATH&amp;quot;，这样重新打开bash后调用的Python和包就是Anaconda安装的版本了。这也是为什么我当时安装完之后运行Python没有发现异常，但是重启之后出错的原因。
4. 虚拟环境 创建虚拟环境的好处有很多，很重要的一个好处就是可以在不同的环境下跑不同的程序，从而解决包的冲突问题。其实虚拟环境的原理也很简单，就是在一个新路径下创建一个新的Python环境，每次进入虚拟环境，就会在$PATH中加入那个路径，这样调用的就是该路径下的Python环境。这样的话，每个环境都对应自己的路径，冲突问题就被解决了。
参考链接 Python Ecosystem an Introduction EnvironmentVariables</description></item></channel></rss>